{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOUGtuqL5aMi++y/ryudy97"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1prEyiAOQzwGyJUpGAh2RjQNb7OqHfsmM"},"id":"I4LPdvrc2wJZ","executionInfo":{"status":"ok","timestamp":1741019973810,"user_tz":420,"elapsed":28533,"user":{"displayName":"Andrew Pownuk","userId":"03168004100943721436"}},"outputId":"ed3687c6-0d65-45b4-b7dc-58b90b749849"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# Install necessary packages (uncomment if needed)\n","!pip install catboost\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Import models from scikit-learn\n","from sklearn.ensemble import (RandomForestRegressor, GradientBoostingRegressor,\n","                              ExtraTreesRegressor, AdaBoostRegressor)\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.neural_network import MLPRegressor\n","from sklearn.tree import DecisionTreeRegressor  # CART model\n","from sklearn.linear_model import (LinearRegression, Lasso, ElasticNet, BayesianRidge, Ridge)\n","from sklearn.svm import SVR\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n","\n","# Import additional models from external libraries\n","from xgboost import XGBRegressor\n","from lightgbm import LGBMRegressor\n","from catboost import CatBoostRegressor\n","\n","# Mount Google Drive (if running in Colab)\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Load dataset from online location\n","data_url = \"https://raw.githubusercontent.com/apownukepcc/ForecastingDailyEmissions/refs/heads/main/SO2TONS_dataset.csv\"\n","data = pd.read_csv(data_url)\n","\n","# Convert the 'date' column to datetime\n","data['date'] = pd.to_datetime(data['date'])\n","\n","# Filter to peak season months (May through August)\n","peak_season_months = [5, 6, 7, 8]\n","data = data[data['date'].dt.month.isin(peak_season_months)]\n","\n","# Define predictors and target variable\n","predictors = ['tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'pres']\n","target = 'Emissions_Load'\n","\n","# Drop rows with missing values (for predictors and target)\n","data = data.dropna(subset=predictors + [target])\n","\n","# Define a comprehensive set of predictive models\n","models = {\n","    \"Random Forest\": RandomForestRegressor(random_state=42),\n","    \"k-NN\": KNeighborsRegressor(n_neighbors=5),\n","    \"Neural Network\": MLPRegressor(hidden_layer_sizes=(50, 50), max_iter=500, random_state=42),\n","    \"Linear Regression\": LinearRegression(),\n","    \"CART\": DecisionTreeRegressor(random_state=42),\n","    \"Gradient Boosting\": GradientBoostingRegressor(random_state=42),\n","    \"SVR\": SVR(kernel='rbf'),\n","    \"Extra Trees\": ExtraTreesRegressor(random_state=42),\n","    \"AdaBoost\": AdaBoostRegressor(random_state=42),\n","    \"Lasso\": Lasso(),\n","    \"ElasticNet\": ElasticNet(random_state=42),\n","    \"XGBoost\": XGBRegressor(random_state=42),\n","    \"LightGBM\": LGBMRegressor(random_state=42),\n","    \"CatBoost\": CatBoostRegressor(random_state=42, verbose=0),\n","    \"Bayesian Ridge\": BayesianRidge(),\n","    \"Ridge\": Ridge(random_state=42)\n","}\n","\n","# Create an empty DataFrame to store predictions for all powerplants\n","all_predictions_table = pd.DataFrame()\n","\n","# To store overall average relative errors per model across all sources\n","overall_rel_errors = {model_name: [] for model_name in models.keys()}\n","\n","# Dictionary to hold summary metrics per source (powerplant)\n","source_summary = {}\n","\n","# Loop over each unique powerplant in the \"Source\" column\n","for source in data['Source'].unique():\n","    print(f\"\\nProcessing predictions for powerplant: {source}\")\n","    data_source = data[data['Source'] == source].copy()\n","\n","    # Check if there is enough data for meaningful predictions\n","    if data_source.shape[0] < 10:\n","        print(f\"Not enough data for {source}, skipping...\\n\")\n","        continue\n","\n","    # Split features and target\n","    X = data_source[predictors]\n","    y = data_source[target]\n","\n","    # Split into training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","    y_test_array = y_test.values\n","\n","    # Dictionaries to hold predictions and performance metrics for this powerplant\n","    predictions = {}\n","    performance_metrics = {}\n","\n","    # For storing aggregated metrics for this source\n","    source_metrics = {}\n","\n","    # Train each model and compute predictions and metrics\n","    for model_name, model in models.items():\n","        model.fit(X_train, y_train)\n","        y_pred = model.predict(X_test)\n","        predictions[model_name] = y_pred\n","\n","        rmse = np.sqrt(mean_squared_error(y_test_array, y_pred))\n","        mae  = mean_absolute_error(y_test_array, y_pred)\n","        r2   = r2_score(y_test_array, y_pred)\n","        mape = np.mean(np.abs((y_test_array - y_pred) / y_test_array)) * 100\n","\n","        performance_metrics[model_name] = {\"RMSE\": rmse, \"MAE\": mae, \"R2\": r2, \"MAPE\": mape}\n","\n","        # Save metrics for overall aggregation across sources\n","        if model_name not in source_metrics:\n","            source_metrics[model_name] = {\"RMSE\": [], \"MAE\": [], \"R2\": [], \"MAPE\": []}\n","        source_metrics[model_name][\"RMSE\"].append(rmse)\n","        source_metrics[model_name][\"MAE\"].append(mae)\n","        source_metrics[model_name][\"R2\"].append(r2)\n","        source_metrics[model_name][\"MAPE\"].append(mape)\n","\n","        # Collect relative error for overall summary\n","        rel_error = np.mean((np.abs(y_pred - y_test_array) / y_test_array) * 100)\n","        overall_rel_errors[model_name].append(rel_error)\n","\n","    # Build predictions table for the current powerplant\n","    pred_table = pd.DataFrame({\n","        \"Date\": data_source.loc[X_test.index, 'date'].values,\n","        \"Actual\": y_test_array\n","    })\n","\n","    for model_name, y_pred in predictions.items():\n","        pred_table[model_name] = y_pred\n","        residual = y_pred - y_test_array\n","        pred_table[model_name + \" Residual\"] = residual\n","        pred_table[model_name + \" Relative Error (%)\"] = (np.abs(residual) / y_test_array) * 100\n","\n","        # Plot predicted vs. actual\n","        plt.figure(figsize=(8, 6))\n","        plt.scatter(y_test_array, y_pred, alpha=0.6, label=model_name)\n","        plt.plot([min(y_test_array), max(y_test_array)], [min(y_test_array), max(y_test_array)], 'k--', label=\"Perfect Fit\")\n","        plt.xlabel(\"Actual Emissions_Load\")\n","        plt.ylabel(\"Predicted Emissions_Load\")\n","        plt.title(f\"{source} - Predicted vs Actual for {model_name}\")\n","        plt.legend()\n","        plt.grid(True)\n","        plt.show()\n","\n","    # Print performance metrics for this powerplant\n","    print(f\"Performance metrics for powerplant {source}:\")\n","    for model_name, metrics in performance_metrics.items():\n","        print(f\"  {model_name}: RMSE={metrics['RMSE']:.2e}, MAE={metrics['MAE']:.2e}, R2={metrics['R2']:.2f}, MAPE={metrics['MAPE']:.2f}%\")\n","\n","    # Add Source column and append to the global predictions table\n","    pred_table[\"Source\"] = source\n","    all_predictions_table = pd.concat([all_predictions_table, pred_table], ignore_index=True)\n","\n","    # Create summary table for this powerplant (average metrics per model)\n","    summary_data = []\n","    for model_name, metrics in source_metrics.items():\n","        avg_rmse = np.mean(metrics[\"RMSE\"]) if metrics[\"RMSE\"] else np.nan\n","        avg_mae  = np.mean(metrics[\"MAE\"])  if metrics[\"MAE\"]  else np.nan\n","        avg_r2   = np.mean(metrics[\"R2\"])   if metrics[\"R2\"]   else np.nan\n","        avg_mape = np.mean(metrics[\"MAPE\"])  if metrics[\"MAPE\"] else np.nan\n","        summary_data.append({\n","            \"Model\": model_name,\n","            \"Avg_RMSE\": avg_rmse,\n","            \"Avg_MAE\": avg_mae,\n","            \"Avg_R2\": avg_r2,\n","            \"Avg_MAPE\": avg_mape\n","        })\n","    summary_df = pd.DataFrame(summary_data)\n","    source_summary[source] = summary_df.copy()\n","\n","    print(f\"\\nSummary for {source} (average metrics):\")\n","    print(summary_df)\n","\n","    # Sort and print best and worst for each metric for this source\n","    metrics_to_sort = {\n","        \"Avg_RMSE\": \"min\",   # lower is better\n","        \"Avg_MAE\": \"min\",    # lower is better\n","        \"Avg_MAPE\": \"min\",   # lower is better\n","        \"Avg_R2\": \"max\"      # higher is better\n","    }\n","    for metric, sort_order in metrics_to_sort.items():\n","        sorted_df = summary_df.sort_values(by=metric, ascending=(sort_order==\"min\"))\n","        best_model = sorted_df.iloc[0][\"Model\"]\n","        worst_model = sorted_df.iloc[-1][\"Model\"]\n","        print(f\"\\nFor {source} sorted by {metric}:\")\n","        print(sorted_df[['Model', metric]])\n","        print(f\"Best {metric}: {best_model}   |   Worst {metric}: {worst_model}\")\n","\n","# Sort the global predictions table by Source and Date\n","all_predictions_table.sort_values(by=[\"Source\", \"Date\"], inplace=True)\n","\n","# Save the global predictions table to CSV on Google Drive\n","csv_path = '/content/drive/My Drive/final_predictions_by_powerplant_extended.csv'\n","all_predictions_table.to_csv(csv_path, index=False)\n","print(f\"\\nGlobal predictions table saved to {csv_path}\")\n","\n","# Compute and print overall average relative error for each model across all powerplants\n","print(\"\\nOverall Average Relative Error (%) for each model across all powerplants:\")\n","for model_name, errors in overall_rel_errors.items():\n","    if errors:\n","        avg_rel_error = np.mean(errors)\n","        print(f\"  {model_name}: {avg_rel_error:.2f}%\")\n","    else:\n","        print(f\"  {model_name}: No data available.\")\n","\n","# Optionally, display a sample of the global predictions table\n","print(\"\\nSample of global predictions table:\")\n","print(all_predictions_table.head())\n"]},{"cell_type":"code","source":[],"metadata":{"id":"pLHKO7JY3Alt"},"execution_count":null,"outputs":[]}]}