{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNHZfLyDcsazXI+Xkuin/8Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J6A_99Q9zMKq","executionInfo":{"status":"ok","timestamp":1742444815170,"user_tz":360,"elapsed":38338,"user":{"displayName":"Andrew Pownuk","userId":"03168004100943721436"}},"outputId":"1d182ac0-d15d-4582-f813-140cbf5da8b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Prediction Results with Additional Accuracy Metrics:\n","              Parameter           MSE      RMSE   R2 Score       MAE  \\\n","0  SO2TONS_per_LOADMWBA  5.215343e-10  0.000023  -1.026429  0.000015   \n","1  SO2TONS_per_LOADMWBT  1.886041e-10  0.000014  -3.190571  0.000001   \n","2  NH3TONS_per_LOADMWBA  1.894064e-07  0.000435  -0.130916  0.000188   \n","3  NH3TONS_per_LOADMWBT  1.566539e-07  0.000396  -0.080655  0.000034   \n","4  NOXTONS_per_LOADMWBA  7.116828e-06  0.002668 -14.400662  0.000436   \n","5  NOXTONS_per_LOADMWBT  7.034303e-06  0.002652 -15.010391  0.000179   \n","6   COTONS_per_LOADMWBA  4.859347e-06  0.002204 -10.715458  0.000259   \n","7   COTONS_per_LOADMWBT  4.857768e-06  0.002204 -10.840120  0.000151   \n","\n","      Median AE  Explained Variance  \n","0  1.086284e-05           -1.013577  \n","1  7.071510e-08           -3.189731  \n","2  1.453538e-04           -0.128308  \n","3  8.544769e-06           -0.079666  \n","4  1.974066e-04          -14.395387  \n","5  2.242496e-06          -14.994094  \n","6  8.827579e-05          -10.710511  \n","7  5.467342e-06          -10.830167  \n","\n","Comparison for specific test date (2022-07-15):\n","                        Actual  Predicted\n","SO2TONS_per_LOADMWBA  0.000031   0.000037\n","SO2TONS_per_LOADMWBT  0.000003   0.000003\n","NH3TONS_per_LOADMWBA  0.000178   0.000270\n","NH3TONS_per_LOADMWBT  0.000015   0.000021\n","NOXTONS_per_LOADMWBA  0.000613   0.000704\n","NOXTONS_per_LOADMWBT  0.000051   0.000054\n","COTONS_per_LOADMWBA   0.000104   0.000088\n","COTONS_per_LOADMWBT   0.000009   0.000007\n","\n","--- ChatGPT Comment on Accuracy ---\n","\n","Based on the provided results, it appears that the predictions for most of the emissions metrics (SO2, NH3, NOX, COTONS per LOADMWBA/BT) have relatively low Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) values, indicating a good level of accuracy in the predictions. However, the R² Score values for some metrics are negative, suggesting that the model may not be capturing the variability in the data well.\n","\n","To improve the accuracy of the predictions, it may be beneficial to consider the following recommendations:\n","1. Feature Engineering: Explore additional features or transformations of existing features that may better capture the relationships between weather conditions and emissions metrics.\n","2. Model Selection: Consider experimenting with different regression models or ensemble methods to see if a different algorithm performs better on the dataset.\n","3. Hyperparameter Tuning: Optimize the hyperparameters of the Decision Tree Regressor to improve its performance on the dataset.\n","4. Data Preprocessing: Ensure that the data is properly preprocessed, including handling missing values, scaling features, and encoding categorical variables.\n","\n","Overall, while the predictions show promise, there is room for improvement in the model's performance. By implementing the above recommendations and further refining the model, it is possible to enhance the accuracy of the predictions for emissions metrics.\n"]}],"source":["# ----------------------------------\n","# 1. Mount Google Drive and Imports\n","# ----------------------------------\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","import asyncio\n","import nest_asyncio\n","import openai\n","\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import (\n","    mean_squared_error,\n","    r2_score,\n","    mean_absolute_error,\n","    median_absolute_error,\n","    explained_variance_score\n",")\n","\n","nest_asyncio.apply()  # Allows asyncio.run() in notebooks\n","\n","# ----------------------------------\n","# 2. Configure OpenAI Client\n","# ----------------------------------\n","\n","# Read your API key from Google Drive\n","with open('/content/drive/MyDrive/key.txt', 'r') as file:\n","    api_key = file.read().strip()\n","\n","# Create a client using the same pattern as your working code\n","client = openai.AsyncOpenAI(api_key=api_key)\n","\n","# ----------------------------------\n","# 3. Load and Preprocess the Dataset\n","# ----------------------------------\n","\n","url = \"https://raw.githubusercontent.com/apownukepcc/spring-2025-datathon/main/009-Dataset-For-Predictions-With-Specific-Emissions.csv\"\n","df = pd.read_csv(url)\n","\n","# Convert 'date' column to datetime\n","df['date'] = pd.to_datetime(df['date'])\n","\n","# Define the specific date to be included in the test set later\n","specific_test_date = pd.to_datetime(\"2022-07-15\")\n","\n","# Ensure the specific test date is in the dataset\n","if specific_test_date not in df['date'].values:\n","    raise ValueError(f\"No data available for the date: {specific_test_date}\")\n","\n","# Extract the row for the specific test date and remove it from the main dataset\n","specific_test_row = df[df['date'] == specific_test_date]\n","df = df[df['date'] != specific_test_date]\n","\n","# Define feature columns (weather parameters)\n","feature_cols = ['tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'pres']\n","\n","# Define target columns (specific emissions metrics)\n","target_cols = [\n","    'SO2TONS_per_LOADMWBA', 'SO2TONS_per_LOADMWBT',\n","    'NH3TONS_per_LOADMWBA', 'NH3TONS_per_LOADMWBT',\n","    'NOXTONS_per_LOADMWBA', 'NOXTONS_per_LOADMWBT',\n","    'COTONS_per_LOADMWBA', 'COTONS_per_LOADMWBT'\n","]\n","\n","# Ensure no missing values in features and targets\n","df = df.dropna(subset=feature_cols + target_cols)\n","\n","# ----------------------------------\n","# 4. Train-Test Split and CART Training\n","# ----------------------------------\n","\n","X = df[feature_cols]\n","y = df[target_cols]\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","\n","# Append the specific test row to the test set (it will appear as the last row)\n","X_test = pd.concat([X_test, specific_test_row[feature_cols]])\n","y_test = pd.concat([y_test, specific_test_row[target_cols]])\n","\n","# Initialize and train the Decision Tree Regressor (CART)\n","cart = DecisionTreeRegressor(\n","    random_state=42,\n","    max_depth=None  # Feel free to adjust hyperparameters\n",")\n","cart.fit(X_train, y_train)\n","\n","# Predict on the test set\n","predictions = cart.predict(X_test)\n","\n","# ----------------------------------\n","# 5. Compute Accuracy Metrics\n","# ----------------------------------\n","\n","mse = mean_squared_error(y_test, predictions, multioutput='raw_values')\n","rmse = np.sqrt(mse)\n","r2 = r2_score(y_test, predictions, multioutput='raw_values')\n","mae = mean_absolute_error(y_test, predictions, multioutput='raw_values')\n","med_ae = median_absolute_error(y_test, predictions, multioutput='raw_values')\n","explained_var = explained_variance_score(y_test, predictions, multioutput='raw_values')\n","\n","results = pd.DataFrame({\n","    'Parameter': target_cols,\n","    'MSE': mse,\n","    'RMSE': rmse,\n","    'R2 Score': r2,\n","    'MAE': mae,\n","    'Median AE': med_ae,\n","    'Explained Variance': explained_var\n","})\n","\n","print(\"Prediction Results with Additional Accuracy Metrics:\")\n","print(results)\n","\n","# Compare predictions with actual values for the specific test date\n","pred_df = pd.DataFrame(predictions, index=y_test.index, columns=target_cols)\n","specific_pred = pred_df.iloc[-1]\n","specific_actual = y_test.iloc[-1]\n","\n","comparison_df = pd.DataFrame({\n","    'Actual': specific_actual,\n","    'Predicted': specific_pred\n","})\n","\n","print(f\"\\nComparison for specific test date ({specific_test_date.date()}):\")\n","print(comparison_df)\n","\n","# ----------------------------------\n","# 6. Prepare Summary for ChatGPT\n","# ----------------------------------\n","\n","summary = f\"\"\"\n","Prediction Results with Additional Accuracy Metrics:\n","{results.to_string(index=False)}\n","\n","Comparison for specific test date ({specific_test_date.date()}):\n","{comparison_df.to_string()}\n","\n","Predictive Method Description:\n","A Decision Tree Regressor (CART) was trained on 80% of the dataset using weather features\n","(tavg, tmin, tmax, prcp, snow, wdir, wspd, pres) to predict emissions metrics (SO2, NH3, NOX, COTONS per LOADMWBA/BT).\n","A specific date (2022-07-15) was held out from the training set and then appended to the test set for a focused prediction comparison.\n","Performance was evaluated using multiple metrics: MSE, RMSE, R² Score, MAE, Median AE, and Explained Variance.\n","\n","Question:\n","Based on the above results and methodology, please provide a comment on the accuracy of these predictions\n","and any recommendations for improvement.\n","\"\"\"\n","\n","# ----------------------------------\n","# 7. Async Function to Query ChatGPT\n","# ----------------------------------\n","async def get_chatgpt_comment(user_message):\n","    response = await client.chat.completions.create(\n","        model=\"gpt-3.5-turbo\",\n","        messages=[{\"role\": \"user\", \"content\": user_message}],\n","        temperature=0.2\n","    )\n","    return response.choices[0].message.content.strip()\n","\n","# ----------------------------------\n","# 8. Send Query and Print Response\n","# ----------------------------------\n","comment_on_accuracy = asyncio.run(get_chatgpt_comment(summary))\n","print(\"\\n--- ChatGPT Comment on Accuracy ---\\n\")\n","print(comment_on_accuracy)\n"]}]}