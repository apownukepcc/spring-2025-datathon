{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMx6z+WK+JirDYQT3v770d+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1nVnUh2BzN7TkgOxfHg-LDW6k7nDIySd1"},"id":"3UwATlZUrvGk","executionInfo":{"status":"ok","timestamp":1740412963934,"user_tz":420,"elapsed":82846,"user":{"displayName":"Andrew Pownuk","userId":"03168004100943721436"}},"outputId":"ace9325b-0457-4de0-af48-9308a8e448f9"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import train_test_split, learning_curve\n","from sklearn.metrics import mean_squared_error, r2_score\n","import matplotlib.pyplot as plt\n","from sklearn.inspection import PartialDependenceDisplay\n","\n","# URLs for datasets\n","datasets = {\n","    \"SO2TONS\": \"https://raw.githubusercontent.com/apownukepcc/ForecastingDailyEmissions/refs/heads/main/SO2TONS_dataset.csv\",\n","    \"NOXTONS\": \"https://raw.githubusercontent.com/apownukepcc/ForecastingDailyEmissions/refs/heads/main/NOXTONS_dataset.csv\",\n","    \"COTONS\": \"https://raw.githubusercontent.com/apownukepcc/ForecastingDailyEmissions/refs/heads/main/COTONS_dataset.csv\"\n","}\n","\n","# Define the peak season months (May through August)\n","peak_season_months = [5, 6, 7, 8]\n","\n","# Define lakes (sources)\n","sources = [\"LAKE-1\", \"LAKE-2\", \"LAKE-3\", \"LAKE-4\"]\n","\n","# Define the specific day for prediction\n","specific_date = pd.Timestamp(\"2022-07-15\")\n","\n","# Initialize a dictionary to store models, predictions, and inputs for verification\n","models = {}\n","predictions = {}\n","\n","# Loop through each dataset (SO2TONS, NOXTONS, COTONS)\n","for parameter, url in datasets.items():\n","    # Load the dataset\n","    data = pd.read_csv(url)\n","\n","    # Convert the 'date' column to datetime\n","    data['date'] = pd.to_datetime(data['date'])\n","\n","    # Filter for peak season\n","    data = data[data['date'].dt.month.isin(peak_season_months)]\n","\n","    # Separate data by source\n","    for source in sources:\n","        source_data = data[data['Source'] == source]\n","\n","        # Check if the source data has enough rows\n","        if source_data.empty or len(source_data) < 10:\n","            print(f\"Not enough data for {parameter} at {source}. Skipping...\")\n","            continue\n","\n","        # Define predictors (e.g., weather features)\n","        predictors = ['tavg', 'tmin', 'tmax', 'prcp', 'snow', 'wdir', 'wspd', 'pres']\n","        target = 'Emissions_Load'\n","\n","        # Drop rows with missing values\n","        source_data = source_data.dropna(subset=predictors + [target])\n","\n","        # Split the data into features (X) and target (y)\n","        X = source_data[predictors]\n","        y = source_data[target]\n","\n","        # Split into train and test sets\n","        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","        # Train a Random Forest Regressor\n","        model = RandomForestRegressor(random_state=42)\n","        model.fit(X_train, y_train)\n","\n","        # Evaluate the model\n","        y_pred = model.predict(X_test)\n","        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","        r2 = r2_score(y_test, y_pred)\n","\n","        print(f\"Model for {parameter} at {source}:\")\n","        print(f\"  RMSE: {rmse:.4f}\")\n","        print(f\"  RÂ²: {r2:.4f}\")\n","\n","        # Save the model\n","        models[(parameter, source)] = model\n","\n","        # ---------------------------\n","        # Plot 1: Predicted vs. Actual\n","        plt.figure(figsize=(8, 6))\n","        plt.scatter(y_test, y_pred, alpha=0.7)\n","        plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--')\n","        plt.xlabel(\"Actual Emissions_Load\")\n","        plt.ylabel(\"Predicted Emissions_Load\")\n","        plt.title(f\"Predicted vs. Actual for {parameter} at {source}\")\n","        plt.grid(True)\n","        plt.show()\n","\n","        # ---------------------------\n","        # Plot 2: Residual Plot\n","        residuals = y_test - y_pred\n","        plt.figure(figsize=(8, 6))\n","        plt.scatter(y_pred, residuals, alpha=0.7)\n","        plt.axhline(0, color='red', linestyle='--')\n","        plt.xlabel(\"Predicted Emissions_Load\")\n","        plt.ylabel(\"Residuals\")\n","        plt.title(f\"Residual Plot for {parameter} at {source}\")\n","        plt.grid(True)\n","        plt.show()\n","\n","        # ---------------------------\n","        # Plot 3: Feature Importance\n","        importances = model.feature_importances_\n","        indices = np.argsort(importances)\n","        plt.figure(figsize=(10, 6))\n","        plt.title(f\"Feature Importances for {parameter} at {source}\")\n","        plt.barh(range(len(indices)), importances[indices], align='center')\n","        plt.yticks(range(len(indices)), [predictors[i] for i in indices])\n","        plt.xlabel(\"Relative Importance\")\n","        plt.show()\n","\n","        # ---------------------------\n","        # Plot 4: Error Distribution Histogram\n","        plt.figure(figsize=(8, 6))\n","        plt.hist(residuals, bins=20, edgecolor='k', alpha=0.7)\n","        plt.xlabel(\"Residual\")\n","        plt.ylabel(\"Frequency\")\n","        plt.title(f\"Error Distribution for {parameter} at {source}\")\n","        plt.grid(True)\n","        plt.show()\n","\n","        # ---------------------------\n","        # Plot 5: Learning Curve\n","        # Reinitialize a new RandomForestRegressor for computing the learning curve\n","        rf = RandomForestRegressor(random_state=42)\n","        train_sizes, train_scores, test_scores = learning_curve(\n","            rf, X, y, cv=5, scoring='neg_mean_squared_error', n_jobs=-1,\n","            train_sizes=np.linspace(0.1, 1.0, 5)\n","        )\n","        # Compute mean error (convert negative MSE to MSE)\n","        train_scores_mean = -np.mean(train_scores, axis=1)\n","        test_scores_mean = -np.mean(test_scores, axis=1)\n","        plt.figure(figsize=(8, 6))\n","        plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training Error (MSE)\")\n","        plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation Error (MSE)\")\n","        plt.xlabel(\"Training Examples\")\n","        plt.ylabel(\"Error (MSE)\")\n","        plt.title(f\"Learning Curve for {parameter} at {source}\")\n","        plt.legend(loc=\"best\")\n","        plt.grid(True)\n","        plt.show()\n","\n","        # ---------------------------\n","        # Plot 6: Partial Dependence Plot for 'tavg'\n","        fig, ax = plt.subplots(figsize=(8, 6))\n","        PartialDependenceDisplay.from_estimator(model, X, features=['tavg'], ax=ax)\n","        plt.title(f\"Partial Dependence Plot for 'tavg' - {parameter} at {source}\")\n","        plt.show()\n","\n","        # ---------------------------\n","        # Predict for a specific day if available\n","        day_data = source_data[source_data['date'] == specific_date]\n","        if not day_data.empty:\n","            # Extract feature values for the specific day\n","            specific_features = day_data[predictors].iloc[[0]]  # Retain feature names\n","            specific_actual = day_data[target].iloc[0]\n","\n","            # Predict emissions/load for the specific day\n","            specific_prediction = model.predict(specific_features)[0]\n","\n","            # Save the prediction and actual value for verification\n","            predictions[(parameter, source)] = {\n","                \"features\": day_data[predictors].iloc[0],\n","                \"actual\": specific_actual,\n","                \"predicted\": specific_prediction\n","            }\n","\n","# Display all predictions at the end\n","print(\"\\nFinal Predictions:\")\n","for key, value in predictions.items():\n","    parameter, source = key\n","    print(f\"{parameter} at {source}:\")\n","    print(f\"  Features: {value['features'].to_dict()}\")\n","    print(f\"  Actual Emissions_Load: {value['actual']:.4f}\")\n","    print(f\"  Predicted Emissions_Load: {value['predicted']:.4f}\")\n","    print()\n"]}]}